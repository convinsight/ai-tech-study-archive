# Image Classification 1

### **ê°•ì˜ ì†Œê°œ**

ìš°ë¦¬ëŠ” ì˜¤ê° ì¤‘ íŠ¹íˆ ì‹œê°ì— ì˜ì¡´í•˜ì—¬ ì‚¬ë¬¼ì„ ë°”ë¼ë³´ê³  ì´í•´í•˜ë©° ì‚´ì•„ê°€ê³  ìˆìŠµë‹ˆë‹¤.ë™ì¼í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì»´í“¨í„°ì— ì ìš©í•œ ì»´í“¨í„° ë¹„ì „ì…ë‹ˆë‹¤. ë³¸ ê°•ì˜ì—ì„œëŠ” ì»´í“¨í„° ë¹„ì „ (CV)ì˜ ì²« ì‹œê°„ìœ¼ë¡œ CVì— ëŒ€í•´ ì§§ê²Œ ì†Œê°œí•˜ê³ , CVì—ì„œ ê°€ì¥ ê¸°ë³¸ì ì¸ task, image clasiificationì„ ì†Œê°œí•©ë‹ˆë‹¤. 

Image Classificationì€ ì‚¬ì§„ì´ ì£¼ì–´ì¡Œì„ ë•ŒÂ  íŠ¹ì • ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ëŠ” taskì…ë‹ˆë‹¤. ì´ë²ˆ ê°•ì˜ì—ì„œëŠ” ë¨¼ì € ê¸°ì¡´ì˜ ë¨¸ì‹ ëŸ¬ë‹ê³¼ êµ¬ë¶„ë˜ëŠ” ë”¥ëŸ¬ë‹ì„ ì‚¬ìš©í•œ Image classificationì˜ íŠ¹ì§•ì— ëŒ€í•´ì„œ ë°°ì›ë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ëŒ€í‘œì ì¸ CNN ëª¨ë¸ì¸ AlexNetì„ ë°°ìš°ê³  ì´ì— ëŒ€í•œ ì‹¤ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. ëìœ¼ë¡œ ê°€ì¥ ìœ ëª…í•œ classification ëª¨ë¸ ì¤‘ í•˜ë‚˜ì¸ VGGNetì— ëŒ€í•´ ë°°ì›ë‹ˆë‹¤.

### **Further Reading**

- VGGNet :Â [https://arxiv.org/pdf/1409.1556.pdf](https://arxiv.org/pdf/1409.1556.pdf)

# Course overview

## Why is visual perception important?

### Artificial Intelligence (AI)

```jsx
The theory and development of computer systems able to perform tasks normally 
requiring human intelligence, such as visual perception, speech recognition, 
decision-making, and translation between languages. 
	--from the Oxford dictionary
```

### Perception to system?

- Developing machine perception is still open research area

### Why is visual perception important?

- Understanding
    - ë‡Œ ì˜ì—­ì˜ 50% ì´ìƒ â†’ visual information ì²˜ë¦¬
- Sensing
    - ì •ë³´ì˜ 75%ëŠ” ëˆˆìœ¼ë¡œë¶€í„°
    

## What is computer vision?

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f76c77b7-09dc-4eee-8650-21aab17366ef/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T221821Z&X-Amz-Expires=86400&X-Amz-Signature=990002a27229198cd2b1bcbff339758be0996323b64b720685760815a06badfd&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/7dca0623-a019-4e28-a821-8713c04b87eb/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T221928Z&X-Amz-Expires=86400&X-Amz-Signature=a14f8e49cba543e927a5f8b68ce1d72db937ec2c374ed7df45f57341814a91cd&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

- Rendering â†’ ì •ë³´ë¥¼ í†µí•´ 2D ì´ë¯¸ì§€ í‘œí˜„

### Visual perception & intelligence

- Input : visual data (image or video)

### Class of visual perception

- Color perception
- Motion perception
- 3D perception
- Semantic-level perception
- Social perception (emotion perception)
- Visuomotor perception

### Our visual perception is imperfect

- ì‚¬ëŒë„ ë˜‘ë°”ë¡œ ëœ ì´ë¯¸ì§€ë¥¼ â€˜ë§ì´â€™ ë´¤ê¸°(= bias) ë•Œë¬¸ì— ê±°ê¾¸ë¡œ ëœ ì´ë¯¸ì§€ë¥¼ êµ¬ë³„ ê°€ëŠ¥

### How to implement?

- Machine Learning
    - ì‚¬ëŒì´ feature extraction

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a8579dee-9d69-42f8-a747-30cc3d7553a2/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222012Z&X-Amz-Expires=86400&X-Amz-Signature=649a31a7dc9f6688eef3eea05f28b81d0e52f9d4ce1b7f8a61eb34870e5b9d89&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

- Deep Learning
<details>
<summary>ğŸ“feature extraction  </summary>
<div markdown="1">       

   - **ì›ë³¸ íŠ¹ì§• ë“¤ì˜ ì¡°í•©ìœ¼ë¡œ ìƒˆë¡œìš´ íŠ¹ì§•ì„ ìƒì„±í•˜ëŠ” ê²ƒì´ë‹¤.**
   - ê³ ì°¨ì›ì˜ ì›ë³¸ feature ê³µê°„ì„ ì €ì°¨ì›ì˜ ìƒˆë¡œìš´ feature ê³µê°„ìœ¼ë¡œ íˆ¬ì˜ì‹œí‚¨ë‹¤. ìƒˆë¡­ê²Œ êµ¬ì„±ëœ feature ê³µê°„ì€ ë³´í†µì€ ì›ë³¸ feature ê³µê°„ì˜ ì„ í˜• ë˜ëŠ” ë¹„ì„ í˜• ê²°í•©ì´ë‹¤.
   - ê°€ì¥ ëŒ€í‘œì ì¸ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ PCA(Principle Component Analysis)ê°€ ìˆë‹¤. PCAë¥¼ ê°„ë‹¨íˆ ì„¤ëª…í•˜ë©´ ê° ë³€ìˆ˜(Feature)ë¥¼ í•˜ë‚˜ì˜ ì¶•ìœ¼ë¡œ íˆ¬ì˜ì‹œì¼°ì„ ë•Œ ë¶„ì‚°ì´ ê°€ì¥ í° ì¶•ì„ ì²«ë²ˆì§¸ ì£¼ì„±ë¶„ìœ¼ë¡œ ì„ íƒí•˜ê³  ê·¸ ë‹¤ìŒ í° ì¶•ì„ ë‘ë²ˆì§¸ ì£¼ì„±ë¶„ìœ¼ë¡œ ì„ íƒí•˜ê³  **ë°ì´í„°ë¥¼ ì„ í˜• ë³€í™˜í•˜ì—¬ ë‹¤ì°¨ì›ì„ ì¶•ì†Œí•˜ëŠ” ë°©ë²•ì´ë‹¤.**
   - ì°¸ê³  : [ê¸°ê³„í•™ìŠµ/feature engineering - ì¸ì½”ë¤, ìƒë¬¼ì •ë³´ ì „ë¬¸ìœ„í‚¤ (incodom.kr)](http://www.incodom.kr/%EA%B8%B0%EA%B3%84%ED%95%99%EC%8A%B5/feature_engineering#h_2c113344b39c04c8599b84f8fa93718c)
   - ì½ì–´ë³´ê¸° : [Feature Extraction Techniques. An end to end guide on how to reduce aâ€¦ | by Pier Paolo Ippolito | Towards Data Science](https://towardsdatascience.com/feature-extraction-techniques-d619b56e31be)

</div>
</details> 
  
  
<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1070890a-ee6a-4123-be3f-009b91c5f8ea/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222039Z&X-Amz-Expires=86400&X-Amz-Signature=a23f1f5e95bd34d0535dea05c5ed888a474f78b32b7cbd6afd88d0404363f3d4&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

## What you will learn in this course

### Fundamental image tasks

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a2a0196e-87c8-423d-9093-7f94ef5fa5a3/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222111Z&X-Amz-Expires=86400&X-Amz-Signature=fd9aa904c6098fe636b327da7ddb7d1c8e9a7eff8196b4e028308568761b7b88&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

### Data augmentation and knowledge distillation

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/643afaea-e0aa-49c7-bb93-6d9db1398f22/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222131Z&X-Amz-Expires=86400&X-Amz-Signature=9c5806fb4cefdac419b28a19ea6dd16dd50dd8f577fbd92f3e9774fab4a3adec&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

<details>
<summary>ğŸ“ knowledge distillation </summary>
<div markdown="1">    
  
- í¬ê³  ë¬´ê±°ìš´ ëª¨ë¸ì˜ ì •ë³´(knowledge)ë¥¼ ì‘ê³  ê°€ë²¼ìš´ ëª¨ë¸ë¡œ ì „ë‹¬í•˜ì—¬ ì‘ê³  ê°€ë²¼ìš´ ëª¨ë¸ì´ ë” ì •í™•í•œ ì¶”ë¡ ì„ í•˜ë„ë¡ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ë¡ 
- Knowledge distillation ì˜ ëª©ì ì€ "ë¯¸ë¦¬ ì˜ í•™ìŠµëœ í° ë„¤íŠ¸ì›Œí¬(Teacher network)ì˜ ì§€ì‹ì„ ì‹¤ì œë¡œ ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” **ì‘ì€ ë„¤íŠ¸ì›Œí¬(Student network)** ì—ê²Œ ì „ë‹¬í•˜ëŠ” ê²ƒ" ì…ë‹ˆë‹¤.
- ì°¸ê³  : [1. Knowledge Distillationì´ë€? :: Time Traveler (tistory.com)](https://89douner.tistory.com/143)
- ì°¸ê³  : [ë”¥ëŸ¬ë‹ ìš©ì–´ ì •ë¦¬, Knowledge distillation ì„¤ëª…ê³¼ ì´í•´ (tistory.com)](https://light-tree.tistory.com/196)

</div>
</details>


### Multi-modal learning (vision + {text, sound, 3D})

- ë‹¤ë¥¸ perceptionê³¼ visionì„ í•¨ê»˜ í•™ìŠµ

### Conditional generative model

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/41c7bf64-2074-4fc8-9ae9-c18dee75552c/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222154Z&X-Amz-Expires=86400&X-Amz-Signature=5d517a0490dc42d2e6135c5530d6f2527b8ee10f7108647decff5de763c6e8f1&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

### Neural network analysis by visualization

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/d02aa956-c9d7-4f38-9f7b-a86602bf42e3/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222216Z&X-Amz-Expires=86400&X-Amz-Signature=f68d31d558d856345d7cb421c3c60282b5b562393e1e9610691b4e13e6e27d27&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

# Image classification

## What is classification?

### Classifier

- mapping function that maps an image to a **category level**

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/26c4b61b-c6ac-48fd-97c3-53ee0884de80/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222234Z&X-Amz-Expires=86400&X-Amz-Signature=1f33520cc82d4b5de8de68be29012c1fd6977f6c8519b62cfdf4d7301cabddd4&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

## An ideal approach for image recognition

- ì„¸ìƒì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ memorize â†’ classification ë¬¸ì œë¥¼ k Nearest Neighbors (k-NN)ìœ¼ë¡œ í•´ê²°
- but, ë¶ˆê°€ëŠ¥
    - âˆµ ëª¨ë“  ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ê²ƒì´ ë¶ˆê°€ëŠ¥
    - âˆµ k-NNí•˜ë ¤ë©´ ë°ì´í„°(ì´ë¯¸ì§€)ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ì •ì˜í•´ì•¼ â†’ ìœ ì‚¬ë„ ì •ì˜ hard
    - âˆµ Time complexity (ex. linear search) â†’ O(n) (n=infinite)
    - âˆµ Memory complexity â†’ O(n) (n=infinite)
<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bfe58c1a-6c5f-456d-ab8a-20b68b13f2ff/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222252Z&X-Amz-Expires=86400&X-Amz-Signature=8905b0dbcd837c0731c94a9384073e98e5eb7026b2794225a123d51c5be2479e&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

### k Nearest Neighbors (k-NN)

- query data ê·¼ë°©ì˜ kê°œì˜ dataë¥¼ ë³´ê³  query dataë¥¼ classify

<img width="30%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c08938b7-7371-47e7-9984-f33f8fb3e300/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222312Z&X-Amz-Expires=86400&X-Amz-Signature=83064e7c7e5d41838f796f79aecba4a8fa0542b85e453bda4f10549a72ccde58&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

<details>
<summary>ğŸ“k-NN  </summary>
<div markdown="1">       
  
- ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì…ë ¥ë˜ì—ˆì„ ë•Œ, ê¸°ì¡´ì˜ ë°ì´í„°ì™€ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ë¹„êµí•¨ìœ¼ë¡œì¨ ìƒˆë¡œìš´ ë°ì´í„°ì™€ ê°€ì¥ ì¸ì ‘í•œ ë°ì´í„° kê°œë¥¼ ì„ ì •í•œë‹¤. ì´ì–´ì„œ, kê°’ì— ì˜í•´ ê²°ì •ëœ ë¶„ë¥˜ë¥¼ ì…ë ¥ëœ ë°ì´í„°ì˜ ë¶„ë¥˜ë¡œ í™•ì •í•œë‹¤. ì¦‰, ìƒˆë¡œ ì…ë ¥ëœ ë°ì´í„°ì™€ ê¸°ì¡´ ë°ì´í„°ë¥¼ ë¹„êµí•¨ìœ¼ë¡œì¨ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìœ ì‚¬í•˜ê²Œ íŒë‹¨ëœ ê¸°ì¡´ ë°ì´í„°ë¡œ ë¶„ë¥˜í•œë‹¤.    
- cf) këŠ” ë³´í†µ í™€ìˆ˜ë¥¼ ë§ì´ ì‚¬ìš©    
- ì°¸ê³  : [kNN(k Nearest Neighbor) ì•Œê³ ë¦¬ì¦˜ (tistory.com)](https://computer-science-student.tistory.com/56)  

</div>
</details>


## Convolutional Neural Networks (CNN)

- ëª¨ë“  dataë¥¼ neural networkì— compress

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b47458e5-5cee-4e22-a729-a5ab76a2d793/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222332Z&X-Amz-Expires=86400&X-Amz-Signature=064c0f98e4f7ab4527ced88123c4f2762d87ed61907479624eecc6310c7b8f2b&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

### visualization of single fully connected layer networks

<details>
<summary>ğŸ“fully connected layer  </summary>
<div markdown="1">     
  
- í•œì¸µì˜ ëª¨ë“  ë‰´ëŸ°ì´ ë‹¤ìŒì¸µì´ ëª¨ë“  ë‰´ëŸ°ê³¼ ì—°ê²°ëœ ìƒíƒœë¡œ, 2ì°¨ì›ì˜ ë°°ì—´ í˜•íƒœ ì´ë¯¸ì§€ë¥¼ 1ì°¨ì›ì˜ í‰íƒ„í™” ì‘ì—…ì„ í†µí•´ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ”ë° ì‚¬ìš©ë˜ëŠ” ê³„ì¸µì…ë‹ˆë‹¤.   
      1. 2ì°¨ì› ë°°ì—´ í˜•íƒœì˜ ì´ë¯¸ì§€ë¥¼ 1ì°¨ì› ë°°ì—´ë¡œ í‰íƒ„í™”   
      2. í™œì„±í™” í•¨ìˆ˜(Relu, Leaky Relu, Tanh,ë“±)ë‰´ëŸ°ì„ í™œì„±í™”   
      3. ë¶„ë¥˜ê¸°(Softmax) í•¨ìˆ˜ë¡œ ë¶„ë¥˜    
- ì°¸ê³  + ì½ì–´ë³´ê¸° : [[ë”¥ëŸ¬ë‹ ë ˆì´ì–´] FC(Fully Connected Layers)ì´ë€? : ë„¤ì´ë²„ ë¸”ë¡œê·¸ (naver.com)](https://blog.naver.com/PostView.nhn?blogId=intelliz&logNo=221709190464)

</div>
</details>

<details>
<summary>ğŸ“FNN VS. CNN </summary>
<div markdown="1">      
  
- CNNì´ ë‚˜ì˜¤ê¸° ì´ì „ ì´ë¯¸ì§€ ì¸ì‹ì€ 2ì°¨ì›ìœ¼ë¡œ ì´ë¯¸ì§€(ì±„ë„ê¹Œì§€ í¬í•¨ 3ì°¨ì›)ë¥¼ 1ì°¨ì› ë°°ì—´ë¡œ ë°”ê¾¼ ë’¤ **FNN (Fully- connected multi layered Neural Network)** ì‹ ê²½ë§ìœ¼ë¡œ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²• ì´ì—ˆë‹¤.
- FNNì˜ ë¬¸ì œì ì€ ì¸ì ‘ í”½ì…€ê°„ì˜ ìƒê´€ê´€ê³„ê°€ ë¬´ì‹œëœë‹¤ëŠ” ê²ƒì´ë‹¤. FNNì€ ë²¡í„° í˜•íƒœë¡œ í‘œí˜„ëœ ë°ì´í„°ë¥¼ ì…ë ¥ ë°›ê¸° ë•Œë¬¸ì— ì´ë¯¸ì§€ë¥¼ ë°˜ë“œì‹œ ë²¡í„°í™” í•´ì•¼ í•œë‹¤. ê·¸ëŸ¬ë‚˜ ì´ë¯¸ì§€ ë°ì´í„°ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì¸ì ‘í•œ í”½ì…€ê°„ì˜ ìƒê´€ê´€ê³„ê°€ ë§¤ìš° ë†’ê¸° ë•Œë¬¸ì— ì´ë¯¸ì§€ë¥¼ **ë²¡í„°í™” (vectorization)í•˜ëŠ” ê³¼ì •ì—ì„œ ì •ë³´ ì†ì‹¤ì´ ë°œìƒí•œë‹¤.**
<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8ce7dfb5-1da3-474b-8ade-21fefc842967/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222503Z&X-Amz-Expires=86400&X-Amz-Signature=bfa32b8dab07d44b45ada0de019f236a212898cf696f87ee953c8691b20cc7e1&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">


- CNNì€ ì´ë¯¸ì§€ì˜ í˜•íƒœë¥¼ ë³´ì¡´í•˜ë„ë¡ í–‰ë ¬ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ì…ë ¥ ë°›ê¸° ë•Œë¬¸ì— ì´ë¯¸ì§€ë¥¼ ë²¡í„°í™” í•˜ëŠ” ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” **ì •ë³´ ì†ì‹¤ì„ ë°©ì§€**í•  ìˆ˜ ìˆë‹¤.
- ì°¸ê³  : [CNN (Convolutional Neural Network) ê°œë… : ë„¤ì´ë²„ ë¸”ë¡œê·¸ (naver.com)](https://m.blog.naver.com/jevida/221841296542)

</div>
</details>


<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/97924849-37f5-40bb-95b6-ebb9010b28fc/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222434Z&X-Amz-Expires=86400&X-Amz-Signature=e305de008399314dbc71123eabe838f1ac507cf9e7b21f9cce690e79bbd2a718&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

- ë¬¸ì œ 1ï¸âƒ£ í‰ê·  ì˜ìƒ(ì´ë¯¸ì§€) ì™¸ì—ëŠ” í‘œí˜„ ë¶ˆê°€ëŠ¥

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/0adaba2f-bb90-4a9e-981a-48aac96b92ca/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222536Z&X-Amz-Expires=86400&X-Amz-Signature=e625831e9caed20f58852ca9f003a9c5ae81fbe018ca2e0e4a808a0b3baea9b3&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

- ë¬¸ì œ 2ï¸âƒ£ test time ë•Œ ë¬¸ì œ ë°œìƒ
    - crop ëœ ì‚¬ì§„ì´ inputìœ¼ë¡œ ë“¤ì–´ì˜¤ë©´, ì´ëŸ° íŒ¨í„´ì€ í•™ìŠµí•œ ì ì´ ì—†ìœ¼ë¯€ë¡œ í‹€ë¦° output ë‚´ë†“ìŒ

<img width="50%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1078c352-89bd-4d41-acb2-9ef84ee63ac6/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222552Z&X-Amz-Expires=86400&X-Amz-Signature=960cc5b690c9be9b45317eebd528eadde08048492aeeff4a208a631367b16d12&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

### Convolution neural networks are ~~fully~~ `locally` connected neural networks

<img width="50%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/28f1617d-f8d1-4603-929f-7d19b28301d5/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222608Z&X-Amz-Expires=86400&X-Amz-Signature=4c16461101681192bb36ac52706a1757f4b7e409e085ec179485b09218760c23&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

- Local feature learning
    - feature 1ê°œ ì–»ê¸° ìœ„í•´ì„œ
        - fully connected â†’ íŒ¨í„´ ë°”ë€Œë©´ í‹€ë¦´ í™•ë¥  â†‘
        - locally connected
- Parameter sharing
    - hidden node(filter) ì¬í™œìš© ê°€ëŠ¥ â†’ parameter ê°œìˆ˜ â†“ + overfitting ë°©ì§€ (âˆµ parameter ê°œìˆ˜ å¤š ì´ë©´, overfitting)

### backboneìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” CNN

- CNN â†’ feature extraction ì—­í• 
- target network head
    - image-level classification
    - classification + regression â†’ object detection
    - pixel-level classification â†’ segmentation
 
<details> <summary>ğŸ“box regression  </summary> <div markdown="1">       

- **predicted box**ê°€ **ground truth box**ì™€ ìœ ì‚¬í•˜ë„ë¡ í•™ìŠµí•˜ëŠ” ê²ƒ
- ì°¸ê³  : [Bounding box regression (tistory.com)](https://better-tomorrow.tistory.com/entry/Bounding-box-regression)

</div>
</details>

<img width="50%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/fb17cf64-b720-40c6-ae33-8d202730c250/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222630Z&X-Amz-Expires=86400&X-Amz-Signature=9766ce1c84d2f3ac38cc47b3ffab4c8084fa26f52b8aff2c8298b5e1d1183aa4&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

<details>
<summary>ğŸ“backbone  </summary>
<div markdown="1">       
  
<img width="50%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/856b571e-88a1-47de-bcc6-0633e9ffab4a/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222654Z&X-Amz-Expires=86400&X-Amz-Signature=072c1837bdd328e4ce0bf09fd27937d2d2aeea1a35f93c2ca28b77ffa12b6833&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">
  
- Backboneì€ ë“±ë¼ˆë¼ëŠ” ëœ»ì¸ë°, ì¦‰ ì²™ì¶”ëŠ” ë‡Œì™€ ëª¸ì˜ ê° ë¶€ìœ„ì˜ ì‹ ê²½ì„ ì´ì–´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤.
- ì…ë ¥: ë‡Œë¥¼ í†µí•´, ì¶œë ¥: íŒ”, ë‹¤ë¦¬ ë¼ê³  ìƒê°í•˜ë©´ backboneì€ ì…ë ¥ì´ ì²˜ìŒ ë“¤ì–´ì™€ì„œ ì¶œë ¥ì— ê´€ë ¨ëœ ëª¨ë“ˆì— ì²˜ë¦¬ëœ ì…ë ¥ì„ ë³´ë‚´ì£¼ëŠ” ì—­í• ì´ë¼ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤.
- ê°œì²´ë¥¼ ê²€ì¶œí•˜ë“  ì˜ì—­ë“¤ì„ ë‚˜ëˆ„ë“  Neural NetworkëŠ” **ì…ë ¥ ì´ë¯¸ì§€ë¡œë¶€í„° ë‹¤ì–‘í•œ featureë¥¼ ì¶”ì¶œ**í•´ì•¼ í•œë‹¤. ê·¸ ì—­í• ì„ **backbone ë„¤íŠ¸ì›Œí¬**ê°€ í•œë‹¤.
- ì°¸ê³  : [ë”¥ëŸ¬ë‹ì—ì„œ Backbone Networkë€? : ë„¤ì´ë²„ ë¸”ë¡œê·¸ (naver.com)](https://blog.naver.com/keeping816/221681396990)

</div>
</details>

<details>
<summary>ğŸ“classification + regression â†’ object detection  </summary>
<div markdown="1">       
  
  
- convolution networkë¥¼ í†µí•´ **classification** + box **regression**(localization)ì„ ìˆ˜í–‰í•œë‹¤
- ì°¸ê³  : [[AI/ë”¥ëŸ¬ë‹] ì§„ì •í•œ ë”¥ëŸ¬ë‹ì„ ìœ„í•œ 3ê°€ì§€ ë¶„ë¥˜ (Classification, Object Detection, Image Segmentation) 2íƒ„ (tistory.com)](https://rubber-tree.tistory.com/133?category=966437)


</div>
</details>
    

# CNN architectures for image classification 1

## History

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/618230e5-2a36-4e71-86e7-43f03c14ebae/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222711Z&X-Amz-Expires=86400&X-Amz-Signature=14de7ada60f86a4f0d1c7354fb3f1bae10f65013a5d9bb47299fe300555a2b1b&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

## AlexNet

### LeNet-5

- by Yann LeCun
- `Conv` - `Pool` - `Conv` - `Pool` - `FC` - `FC`
- Convolution : 5x5 filters with stride 1
- Pooling : 2x2 max pooling with stride 2
<details>
<summary>ğŸ“ pooling layer </summary>
<div markdown="1">       
  
1. input sizeë¥¼ ì¤„ì„(Down Sampling).
  - í…ì„œì˜ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ì—­í• ì„ í•œë‹¤.
2. overfittingì„ ì¡°ì ˆ
  - input sizeê°€ ì¤„ì–´ë“œëŠ” ê²ƒì€ ê·¸ë§Œí¼ ì“¸ë°ì—†ëŠ” parameterì˜ ìˆ˜ê°€ ì¤„ì–´ë“œëŠ” ê²ƒì´ë¼ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤. í›ˆë ¨ë°ì´í„°ì—ë§Œ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê³¼ì í•©(overfitting)ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤.
3. íŠ¹ì§•ì„ ì˜ ë½‘ì•„ë‚¸ë‹¤.
  - poolingì„ í–ˆì„ ë•Œ, íŠ¹ì •í•œ ëª¨ì–‘ì„ ë” ì˜ ì¸ì‹í•  ìˆ˜ ìˆë‹¤.
4. ì§€ì—­ì  ì´ë™ì— ë…¸ì´ì¦ˆë¥¼ ì¤Œìœ¼ë¡œì¨ ì¼ë°˜í™” ì„±ëŠ¥ì„ ì˜¬ë ¤ì¤€ë‹¤.
  - max poolingì˜ ê²½ìš° ì£¼ì–´ì§„ í”½ì…€ì¤‘ í°ê²ƒë§Œ ë½‘ê¸°ë•Œë¬¸ì— ëª¨ì–‘ì´ ì¡°ê¸ˆ ë‹¬ë¼ì§€ëŠ” íŠ¹ì„±ì„ ê°€ì§€ê³  ìˆë‹¤
- ì°¸ê³  : [[ CNN ] poolingì´ë€? (tf.keras.layers.MaxPool2D) (tistory.com)](https://supermemi.tistory.com/16)

</div>
</details>    


### AlexNet

- **LeNet-5ì™€ì˜ ì°¨ì´ì **
    - **bigger** (7 hidden layers + 605k neurons + 60 million parameters)
    - trained with **ImageNet**
    - **ReLU** (activation function) + **dropout** (regularization technique)
- **overall architecture**
    - `Conv` - `Pool` - `LRN` - `Conv` - `Pool` - `LRN` - `Conv` - `Conv` - `Conv` - `Pool` - `FC` - `FC` - `FC`
    
    <img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e528d672-cdd1-4837-aff0-4fec614c6709/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222728Z&X-Amz-Expires=86400&X-Amz-Signature=8ed4113df27a07b6050b7f7270b6e4d1bc5afb86a33ae5171330e45f6e92ac58&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">
    
    - (ìœ„ì˜ ê·¸ë¦¼) GPU 2ì¥ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì‚¬ìš© (ë‹¨, LRN ì‚¬ìš© O)
        - ì¤‘ê°„ì¤‘ê°„ activation map cross ì¼ì–´ë‚¨
        
    <img width="50%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bd5d3e4a-fb85-43d4-99ea-c3eeb8157636/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222758Z&X-Amz-Expires=86400&X-Amz-Signature=3e68970b64c9b99f7af80413f8c0b59255c7580a3492f1d7db61c5c5715d3c54&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">
    
    - (ìœ„ì˜ ê·¸ë¦¼) GPU 1ì¥ì„ ì‚¬ìš© (ë‹¨, LRN ì‚¬ìš© X)
<details>
<summary>ğŸ“ activation map </summary>
<div markdown="1">     
  
- í•˜ë‚˜ì˜ **convolution filter**ê°€ ìˆœì°¨ì ìœ¼ë¡œ input ë°ì´í„°ë¥¼ ê±°ì¹˜ê²Œ ë˜ë©´, í•˜ë‚˜ì˜ **map í˜•íƒœì˜ ê²°ê³¼ê°’**ì´ ë‚˜ì˜¤ê²Œ ë˜ëŠ”ë°, ì´ë¥¼ feature mapì´ë¼ê³  í•©ë‹ˆë‹¤.
- ì´ë•Œ, feature mapì—ì„œ activation functionì„ ì ìš©í•œ ê²°ê³¼ë¥¼ activation mapì´ë¼ê³  í•©ë‹ˆë‹¤.
- ì°¸ê³  : [1. Activation Map :: Time Traveler (tistory.com)](https://89douner.tistory.com/260#:~:text=%ED%95%98%EB%82%98%EC%9D%98%20conv%20filter%EA%B0%80%20%EC%88%9C%EC%B0%A8%EC%A0%81%EC%9C%BC%EB%A1%9C%20input%20%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC,or%20activation%20map%EC%9D%B4%EB%9D%BC%EA%B3%A0%20%ED%95%A9%EB%8B%88%EB%8B%A4.)
- ì°¸ê³  : [[Deep Learning] í—·ê°ˆë¦¬ëŠ” ê¸°ë³¸ ìš©ì–´ ëª¨ìŒì§‘ â€” Constructing Future (tistory.com)](https://jisuhan.tistory.com/34)
    

</div>
</details>   

<details>    
<summary>ğŸ“ tensor â†’ vector </summary>
<div markdown="1">       
  
- CNNì—ì„œ Convolution Layerì™€ Pooling Layerë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê±°ì¹˜ë©´ì„œ ì£¼ìš” íŠ¹ì§•ë§Œ ì¶”ì¶œë˜ëŠ”ë° ì´ ë•Œ ì¶”ì¶œëœ ì£¼ìš” íŠ¹ì§•ì€ 2ì°¨ì› ë°ì´í„°ë¡œ ì´ë£¨ì–´ì ¸ ìˆì§€ë§Œ fc layer(Dense)ì™€ ê°™ì´ ë¶„ë¥˜ë¥¼ ìœ„í•œ í•™ìŠµ ë ˆì´ì–´ì—ì„œëŠ” 1ì°¨ì› ë°ì´í„°ë¡œ ë°”ê¾¸ì–´ì„œ í•™ìŠµì´ ë˜ì–´ì•¼ í•œë‹¤.Â **ì´ë•Œ Flatten Layerê°€ 2ì°¨ì› ë°ì´í„°ë¥¼ 1ì°¨ì› ë°ì´í„°ë¡œ ë°”ê¾¸ëŠ” ì—­í• ì„ í•œë‹¤.**

<img width="50%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/3424f94c-066c-433f-9ffe-0650abad4cb2/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222820Z&X-Amz-Expires=86400&X-Amz-Signature=92905a67c19e8123eece5cd19a7195a20299d7bd99cb410f37e6853cec49b084&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

- ì°¸ê³  : [Tensorflow 2.0 - ê° Layerë³„ ì—­í•  ê°œë… ë° íŒŒë¼ë¯¸í„° íŒŒì•… (tistory.com)](https://jeongminhee99.tistory.com/121)

</div>
</details>


<details>
<summary>ğŸ“ average pooling VS. flatten ? </summary>
<div markdown="1">       
  
  
- `Flatten Layer`ë¥¼ ì´ìš©í•´ì„œ ì…ë ¥ë°›ì€ ê°’ì„ êµ‰ì¥íˆ ê¸´ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ë§Œë“  ë‹¤ìŒ, ê·¸ ë²¡í„°ë¥¼ FC Layerì— ë„£ëŠ” ë°©ì‹ìœ¼ë¡œ í•˜ë‚˜í•˜ë‚˜ ë§¤í•‘í•´ì„œ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í–ˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œÂ **ê³µê°„ì  ì •ë³´ë„ ë§ì´ ìƒì–´**ë²„ë¦¬ëŠ”ë°ë‹¤ê°€, êµ‰ì¥íˆ ë§ì€ íŒŒë¼ë¯¸í„°, ì¦‰Â **ê°€ì¤‘ì¹˜ê°€ ë§ì´ í•„ìš”**í•˜ê³ , VGGNetì˜ ê²½ìš° ì´ ë¶€ë¶„ì´ ì „ì²´ ê³„ì‚°ëŸ‰ì˜ 85%ë¥¼ ì°¨ì§€í–ˆìŠµë‹ˆë‹¤. ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ë¥¼ ì•„ë¬´ë¦¬ ìŒ“ì•„ë„ FC Layer í•˜ë‚˜ë¥¼ ëª» ë”°ë¼ê°ˆ ì •ë„ì…ë‹ˆë‹¤.
- `Global Average Pooling layer`ëŠ” **ë¶„ë¥˜í•  í´ë˜ìŠ¤ ìˆ˜ë§Œí¼ feature mapì„ ë§ˆì§€ë§‰ì— ìƒì„±**í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, feature mapì´ 6ê°œë‹ˆê¹Œ ë¶„ë¥˜í•  í´ë˜ìŠ¤ ìˆ˜ê°€ 6ê°œë¼ê³  ê°€ì •í•©ì‹œë‹¤. ê·¸ëŸ¼ ê·¸ feature map ì•ˆì— ìˆëŠ” íŠ¹ì§•ê°’ë“¤ì˜ í‰ê· ì„ êµ¬í•´ì„œ ê°ê°ì˜ ì¶œë ¥ ë…¸ë“œì— ë°”ë¡œ ì…ë ¥í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ê° feature mapì˜ í‰ê· ì´ 7, 4, 8, 6, 3, 5ê°€ ë‚˜ì™”ë‹¤ê³  í•©ì‹œë‹¤.
        - ì¦‰, ë‹¨ìˆœíˆ **ië²ˆì§¸ feature mapì˜ í‰ê· ê°’ì„ êµ¬í•´ì„œ ië²ˆì§¸ ì¶œë ¥ ë…¸ë“œì— ì…ë ¥í•˜ëŠ” ê²ƒ**
        ì…ë‹ˆë‹¤.  
- GAPì˜ ì¥ì 

        1. Location ì •ë³´ë¥¼ FC Layerë³´ë‹¤ ì ê²Œ ìƒëŠ”ë‹¤.

        2. íŒŒë¼ë¯¸í„°ë¥¼ ì°¨ì§€í•˜ì§€ ì•Šì•„ ê³„ì‚° ì†ë„ê°€ ë¹ ë¥´ë‹¤.

        3. íŒŒë¼ë¯¸í„°ê°€ ë§ì•„ì§€ì§€ ì•Šê¸° ë•Œë¬¸ì— ì˜¤ë²„í”¼íŒ…ì„ ë°©ì§€í•œë‹¤.

        4. feature map ì•ˆì˜ ê°’ë“¤ì˜ í‰ê· ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— global context ì •ë³´ë¥¼ ê°€ì§„ë‹¤.

- ì°¸ê³  : [GAP (Global Average Pooling) : ì „ì—­ í‰ê·  í’€ë§ (tistory.com)](https://mole-starseeker.tistory.com/66)

</div>
</details>

        
- **deprecated components**
    - 1ï¸âƒ£ Local Response Normalization (LRN) â†’ Batch normalization ì‚¬ìš©            
    - 2ï¸âƒ£ 11x11 convolution filter  â†’ í¬ê¸°ê°€ í° filter ì‚¬ìš© X
        - The filter size â†‘ â†’ the input size of the image â†‘
            - LeNet: 28x28
            - AlexNet: 227x227
        - Larger size **filters** are used to cover **a wider range of the input image**
    - 3ï¸âƒ£ Receptive field in CNN
        - (ê°€ì •) KxK Conv + stride 1 + PxP pooling layer
            - â†’ input size = (P+K-1) X (P+K-1)
            - ì¼ë°˜ì ì¸ conv output layer êµ¬í•˜ëŠ” ê³µì‹ê³¼ ë™ì¼
            - (ì•„ë˜ ê·¸ë¦¼) Layer i (input layer) â†” Layer i+1 (pooling layer)
            
            <img width="30%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/17be9a27-7150-46b8-96d3-c809e1dae14f/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T222952Z&X-Amz-Expires=86400&X-Amz-Signature=2b96ca4547b8a91b3314c6943475a58c02fdcca07e8cab85df6d40e3043c25de&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

<details>
<summary>ğŸ“LRN (local response normalization)  </summary>
<div markdown="1">    
  
- `ReLU`ëŠ” ì–‘ìˆ˜ì˜ ë°©í–¥ìœ¼ë¡œëŠ” ì…ë ¥ì˜ ê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ê·¸ë ‡ê²Œ ë˜ë©´, Convë‚˜ Pooling ì‹œ ë§¤ìš° ë†’ì€ í•˜ë‚˜ì˜ í”½ì…€ê°’ì´ ì£¼ë³€ì˜ í”½ì…€ì— ì˜í–¥ì„ ë¯¸ì¹˜ê²Œ ë©ë‹ˆë‹¤. â†’ overfitting ê°€ëŠ¥ (âˆµ training dataì—ë§Œ featureê°€ í¬ê²Œ ë°˜ì‘í–ˆìœ¼ë¯€ë¡œ)
- ì´ëŸ° ë¶€ë¶„ì„ ë°©ì§€(= í•œ filterì—ì„œë§Œ ê³¼ë„í•˜ê²Œ activate ë˜ëŠ” ê²ƒì„ ë°©ì§€)í•˜ê¸° ìœ„í•´ì„œ ë‹¤ë¥¸ activation mapì˜ ê°™ì€ ìœ„ì¹˜ì— ìˆëŠ” í”½ì…€ë¼ë¦¬ `normalization`ì„ ì§„í–‰í•©ë‹ˆë‹¤.
- ì°¸ê³  : [LRN(Local Response Normalization) ì´ë€ ë¬´ì—‡ì¸ê°€?(feat. AlexNet) :: Taegu (tistory.com)](https://taeguu.tistory.com/29)
- ì°¸ê³  : [AlexNet: ImageNet Classification wtih Deep Convolutional Neural Networks Curaai00's Deep Learning Blog (tistory.com)](https://curaai00.tistory.com/4)
- ì½ì–´ë³´ê¸° : [AlexNet (tistory.com)](https://eremo2002.tistory.com/112)

</div>
</details>

<details>
<summary>ğŸ“Receptive field  </summary>
<div markdown="1">       
  
- Receptive FieldëŠ” **filterê°€ í•œë²ˆì— ë³´ëŠ” ì˜ì—­**ìœ¼ë¡œ ìƒê°í•˜ë©´ ë©ë‹ˆë‹¤. ì¼ë°˜ì ì¸ 3x3 filter sizeëŠ” receptive fieldê°€ 3x3 ì´ë¯¸ì§€ ì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ëŸ¬í•œ layerë¥¼ ë‘ê°œ, ì„¸ê°œ ìŒ“ìœ¼ë©´ receptive filedê°€ 5x5, 7x7 ì´ëŸ°ì‹ìœ¼ë¡œ ëŠ˜ì–´ë‚˜ê²Œ ë©ë‹ˆë‹¤. Receptive fieldê°€ ëŠ˜ì–´ë‚œë‹¤ëŠ” ê²ƒì€ outputì„ ê³„ì‚°í• ë•Œ ì‚¬ìš©í•˜ëŠ” ì •ë³´ì˜ ì–‘ì´ ë§ë‹¤ëŠ” ê²ƒ ì…ë‹ˆë‹¤.
- ì •ë³´ì˜ ì–‘ì´ ëŠ˜ì–´ë‚˜ë©´, ì„±ëŠ¥ì´ ì¢‹ì•„ì§ˆ í™•ë¥ ë„ ë†’ì•„ì§€ì§€ë§Œ, í•™ìŠµí•´ì•¼ í•  ì–‘ì´ ë§ì•„ì„œ ì—°ì‚°ëŸ‰ì´ ì¦ê°€í•˜ê²Œ ë˜ëŠ” ë‹¨ì ë„ ìˆìŠµë‹ˆë‹¤. ì´ **Receptive fieldë¥¼ ë†’ì´ê¸° ìœ„í•´ì„œ filterì˜ í¬ê¸°ë¥¼ í‚¤ìš°ê±°ë‚˜, layerë¥¼ ëŠ˜ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜ëŠ” pooling ë“±ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒë„ receptive fieldë¥¼ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.** Polingì˜ ê²½ìš° ì—°ì‚°ëŸ‰ ê¹Œì§€ ê°ì†Œí•  ìˆ˜ ìˆì§€ë§Œ ì •ë³´ì˜ ì†ì‹¤ì„ ê°€ì ¸ì˜¬ ìˆ˜ë„ ìˆì£ .
- ì°¸ê³  : [https://dataplay.tistory.com/29](https://dataplay.tistory.com/29)

</div>
</details>

<details>
<summary>ğŸ“output layer size ìˆ˜ì‹  </summary>
<div markdown="1">   
  
<img width="50%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e95d66e4-b64c-4057-ba29-54aebf2930f9/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T223020Z&X-Amz-Expires=86400&X-Amz-Signature=7e198102c71adf82bbf5ee5e148373447979cf430366950e846817f712cfa3e9&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

- ì°¸ê³  : [06. í•©ì„±ê³± ì‹ ê²½ë§ - Convolutional Neural Networks (tistory.com)](https://excelsior-cjh.tistory.com/180)

</div>
</details>


## VGGNet

- Deeper architecture â†’ 16, 19 layers
- Simpler architecture
    - LRN X
    - 3x3 Convolution + 2x2 max pooling (11x11 Convolution X)
- Better performance
    - AlexNet ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ìŒ (2nd in ILSVRC14)
- overall architecture

<img align="left" width="25%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b15c81c5-486f-4d19-af87-6d2aa6abd4d8/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T035753Z&X-Amz-Expires=86400&X-Amz-Signature=ecf5b78e287225c83d445dbf39ee1bb19877c99847014bb18160895cde662895&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">


`output`

- 3 fully-connected (FC) layers

`Key design choices`

- 3x3 convolution filters with stride 1
- 2x2 max pooling operations

â‡’ Using **many** **3x3 conv layers** instead of a
**small** number of **larger conv filters**

- Keeping receptive field sizes large enough (âˆµ ì‘ì€ kernel sizeì˜ conv layerë„ ë§ì´ ìŒ“ìœ¼ë©´, receptive field í¬ê¸° å¤§)
- Deeper with more non-linearities
- Fewer parameters

`Input`

- 224x224 RGB images (same with AlexNet)
- Subtracting mean RGB values of training images â‡’ normalize

<details>
<summary>ğŸ“subtracting RGB mean í•˜ëŠ” ì´ìœ   </summary>
<div markdown="1">       

 - **Mean subtraction**ì€ ê°€ì¥ ì¼ë°˜ì ì¸ ì „ì²˜ë¦¬ í˜•ì‹ì´ë‹¤. ì´ ë°©ë²•ì€Â ë°ì´í„°ì˜Â ëª¨ë“  ê°œë³„*í”¼ì³*ì— **ê·¸Â í‰ê· ì„ ë¹¼ëŠ” ê²ƒ**ì´ë‹¤. ì´ì— ëŒ€í•œ ê¸°í•˜í•™ì  í•´ì„ì€ ë°ì´í„°ì˜ **ëª¨ë“  ì°¨ì›ì— ëŒ€í•œÂ ë¶„í¬ì˜ ì¤‘ì‹¬ì„ ì›ì ìœ¼ë¡œ ì´ë™**í•˜ëŠ” ê²ƒì´ë‹¤.
- **Unnormalized**ì˜ ê²½ìš°, ì•ë’¤ë¡œ ì™”ë‹¤ ê°”ë‹¤ í•˜ë©´ì„œ ìˆ˜ë§ì€ ë‹¨ê³„ë¥¼ ê±°ì³ ìµœì ê°’ì— ë„ë‹¬í•˜ê²Œ ëœë‹¤. ë˜í•œ, í•™ìŠµë¥ (Learning Rate)ë¥¼ ì‘ê²Œ ì„¤ì • í•´ì•¼ í•œë‹¤.
- ë°˜ë©´ì—, **Normalied**ì˜ ê²½ìš° ì–´ë””ì„œ ì‹œì‘í•˜ë“  ì‰½ê²Œ ìµœì ê°’ì— ë„ë‹¬í•  ìˆ˜ ìˆìœ¼ë©°, í•™ìŠµë¥ ì„ ìƒëŒ€ì ìœ¼ë¡œ ë†’ì—¬ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë•Œë¬¸ì— **ë¹ ë¥´ê²Œ í›ˆë ¨ì‹œí‚¬ ìˆ˜ ìˆë‹¤.**
- ì°¸ê³  : [cs231n: Setting up the data and the model (tistory.com)](https://fabj.tistory.com/52)

</div>
</details>   

`Other details`

- **ReLU** for non-linearity
- No local response normalization (LRN X)

# Reference

### Course overview

- Thompson, Margaret Thatcher: A New Ilusion, Perception 1980
- Kirillov et al., Panoptic Segmentation, CVPR 2019
- Gordon et al., Depth from Videos in the Wild: Unsupervised Monocular Depth Learning from Unknown Cameras, ICCV 2019
- Huang et al., Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization, ICCV 2017
- Selvaraju et al., Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization, ICCV 2017

### CNN architectures for image classification 1

- Lecun et al., Gradient-based Learning Applied to Document Recognition, Proceedings of the IEEE 1998
- Krizhevsky et al., ImageNet Classification with Deep Convolutional Neural Networks, NIPS 2012
- Simonyan and Zisserman, Very Deep Convolutional Networks for Large-Scale Image Recognition, ICLR 2015
