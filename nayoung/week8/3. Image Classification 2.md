# Image Classification 2

### **ê°•ì˜ ì†Œê°œ**

ì´ë²ˆ ê°•ì˜ì—ì„œëŠ” 1ê°• Image Classificationì— ì´ì–´ì„œ ëŒ€í‘œì ì¸ CNN ëª¨ë¸ë“¤ì— ëŒ€í•´ ë°°ì›ë‹ˆë‹¤.

ë¨¼ì € VGGNetê³¼ ë¹„ìŠ·í•œ ì‹œê¸°ì— ë“±ì¥í•œ GoogLeNetì„ ì‹œì‘ìœ¼ë¡œ, ì§€ê¸ˆë„ ë§ì´ ì“°ì´ê³  ìˆëŠ” ResNetì— ê³µë¶€í•˜ê³  ì‹¤ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.

ì´ ì™¸ì—ë„ ì¶”ê°€ì ìœ¼ë¡œ ëª‡ê°€ì§€ CNN ëª¨ë¸ë“¤ì— ëŒ€í•œ ì†Œê°œë¥¼ í•©ë‹ˆë‹¤.

ëìœ¼ë¡œ 1ê°•ê³¼ 3ê°•ê¹Œì§€ ë‹¤ë£¬ 4ê°€ì§€ ëª¨ë¸ (AlexNet, VGGNet, GoogLeNet, ResNet)ì— ëŒ€í•˜ì—¬ ë©”ëª¨ë¦¬ ì¸¡ë©´ê³¼ ê³„ì‚° íš¨ìœ¨ ê´€ì ì—ì„œ ë¹„êµ ë¶„ì„ì„ í•©ë‹ˆë‹¤.

### **Further Reading**

- ResNet:Â [https://arxiv.org/pdf/1512.03385.pdf](https://arxiv.org/pdf/1512.03385.pdf)

# Problems with deeper layers

## Going deeper with convolutions

### The neural network is getting deeper and wider

- Deeper networks learn **more powerful features**
    - âˆµ Larger **receptive fields**
    - âˆµ More **capacity and non-linearity**
- But, getting deeper and deeper always works better?

## Hard to optimize

### Deeper networks are harder to optimize

- Gradient vanishing / exploding
- Computationally complex
    - âˆµ ê¹Šê²Œ ìŒ“ì„ìˆ˜ë¡ ê³„ì‚° ë³µì¡ë„ â†‘
- Degradation problem
    - parameter ìˆ˜ â†‘ë¼ì„œ overfitting ë¬¸ì œë¡œ ì˜ˆìƒí–ˆì§€ë§Œ, ì‚¬ì‹¤ degradation ë¬¸ì œ

# CNN architectures for image classification 2

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/618230e5-2a36-4e71-86e7-43f03c14ebae/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T230448Z&X-Amz-Expires=86400&X-Amz-Signature=f279e0fc5acea80532cceb21b07a4a8c5c4bc573835a6da72fb67594bf783460&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

## GoogLeNet

### Inception module

- Apply multiple filter operations on input activation from the previous layer
    - â†’ í•˜ë‚˜ì˜ layerì— ë‹¤ì–‘í•œ í¬ê¸°ì˜ conv filterë¥¼ ì‚¬ìš© â‡’ ì—¬ëŸ¬ ì¸¡ë©´ì˜ activation ê´€ì°° (= width í™•ì¥)
    - 1x1, 3x3, 5x5 `convolution filters`
    - 3x3 `pooling` operation
- **Concatenate** all filter outputs together **along the channel axis**
- The increased network size increases the use of **computational resources**
    - âˆµ í•˜ë‚˜ì˜ layerì— ì—¬ëŸ¬ ê°œì˜ filter ì¡´ì¬ â†’ ê³„ì‚° ë³µì¡ë„ â†‘
    - Use **1x1 convolutions â†’ bottleneck layer** â‡’ **the number of channels â†“**
    
<details>
<summary>ğŸ“channel-wise concatenate  </summary>
<div markdown="1">       

- ê° feature mapë“¤ì˜ ê²°ê³¼ëŠ” ê·¸ **í¬ê¸°ë¥¼ í•˜ë‚˜ë¡œ í†µì¼ë˜ê²Œ ì„¤ê³„**í•´ì•¼ Concat ì—°ì‚°ì´ ê°€ëŠ¥í•´ì§„ë‹¤.
- ì°¸ê³  : [CNN ëª¨ë¸ íƒêµ¬ (3) - GoogLeNet : ë„¤ì´ë²„ ë¸”ë¡œê·¸ (naver.com)](https://blog.naver.com/PostView.nhn?blogId=siniphia&logNo=221376360476)

</div>
</details>

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/464ad447-19cf-4e2e-befe-7ac407861662/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T230514Z&X-Amz-Expires=86400&X-Amz-Signature=93bc69abd6832c2460286bb4acefb66bdde6962419c8a684212dae8207bb3446&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

### 1x1 convolutions

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c4cb4a2b-85f1-4d2e-bb6b-863da8e7f6e7/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T230534Z&X-Amz-Expires=86400&X-Amz-Signature=43edcc28a5f4a12660757379529864f09ed285e53d0f3d3b810e810a204a53e2&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">


<details>
<summary>ğŸ“1x1 convolution  </summary>
<div markdown="1">       
<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ff4e1f38-1c4e-4491-b387-02a5b4211227/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T230852Z&X-Amz-Expires=86400&X-Amz-Signature=72c1d4f4b28ee24584642ce47299cffbd6ed943921c8f2e5158acd34d1ca0736&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">   

- 1x1 convolutionì˜ ì¥ì 
    1. Channel ìˆ˜ ì¡°ì ˆ â†’ 1x1 convolutionì˜ filter ê°œìˆ˜ = feature mapì˜ channel ìˆ˜ 
    2. ì—°ì‚°ëŸ‰ ê°ì†Œ(Efficient)
    3. ë¹„ì„ í˜•ì„±(Non-linearity)
- ì°¸ê³  : [1x1 convolutionì´ë€, :: ëŒ€í•™ì›ìƒì´ ì‰½ê²Œ ì„¤ëª…í•´ë³´ê¸° (tistory.com)](https://hwiyong.tistory.com/45)
- ê·¸ë¦¼ ì°¸ê³  : [[DL] 1x1 convolutionì€ ë¬´ì—‡ì´ê³  ì™œ ì‚¬ìš©í• ê¹Œ? | Sociological Imagination (euneestella.github.io)](https://euneestella.github.io/research/2021-10-14-why-we-use-1x1-convolution-at-deep-learning/)

</div>
</details>

    
### Overall architecture

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e7492463-777f-44ef-890b-42672d02db1b/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T230622Z&X-Amz-Expires=86400&X-Amz-Signature=a6612c9d84df5842765ef9d37749778cb2a9fbbc1ab0eee93cda48da35ed8f27&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

- `stem network`
    - vanilla convolution networks
- `Stacked inception modules`
- `Auxiliary classifiers`
    - gradientë¥¼ ì£¼ì… â†’ gradient vanishing ë¬¸ì œ í•´ê²°
- `Classifier output`
    - a single FC layer â†’ í•˜ë‚˜ì˜ fc layerë¡œ softmax score ì‚°ì¶œ

### Auxiliary classifier
<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/91ec5de2-aeda-4daf-bedb-6ce41a5aa0d9/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T230656Z&X-Amz-Expires=86400&X-Amz-Signature=742047d2ac77b0423329681a4a5bb9dd291b04eed994ef48e2b5430839c53d80&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

- lower layerì— additional gradient ì£¼ì… â†’ vanishing gradient ë¬¸ì œ í•´ê²°
- trainingì—ì„œë§Œ ì‚¬ìš© â†’ testì—ì„œëŠ” ì‚¬ìš© X

## ResNet

### Revolutions of depth

- building ultra-deeper than any other networks

### Degradation problem

- depth of network â†‘ â†’ accuracy (rapidly) â†“
    - not by `overfitting` but by `optimization`
    - overfittingìœ¼ë¡œ ì„¤ëª…í•˜ë ¤ë©´, training errorì—ì„œëŠ” 56-layerê°€ 20-layerë³´ë‹¤ëŠ” ë‚®ì•˜ì–´ì•¼
    - optimization ë¬¸ì œ â†’ gradient vanishing / exploding ê´€ë ¨
    
    <img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/b35ce100-338f-4375-9f80-a14c7d6d84ad/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T230751Z&X-Amz-Expires=86400&X-Amz-Signature=4e607e5844a2443815c688c62c163df02aed8fcf46a550ca51937a9d6e50f79b&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">
    

### Hypothesis

- Plain layer
    - As the layers get **deeper** â†‘ â†’ **hard** to learn good H(x) directly
- Residual block
    - `Target function`
        - H(x) = F(x) + x â†’ Shortcut connection
    - `Residual function`
        - F(x) = H(x) - x

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/65276ec5-9f5c-4acf-b9ac-9be88bc47204/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T231025Z&X-Amz-Expires=86400&X-Amz-Signature=38b104937f4a2520ff4d5df27e2dc9892e0d7c9ec8dae168a1653013cc8040c1&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

### Analysis of residual connection

- gradientëŠ” (plain layersì— ë¹„í•´) ë¹„êµì  shorter pathë¥¼ ì´ë™ â†’ gradient vanishing ë¬¸ì œ í•´ê²°
- Residual networkì˜ connection ê²½ë¡œëŠ” O(2^n)ì˜ ê²½ìš°ì˜ ìˆ˜ ì¡´ì¬ â†’ block í•˜ë‚˜ê°€ ì¶”ê°€ë  ë•Œë§ˆë‹¤ ê²½ìš°ì˜ ìˆ˜ 2ë°°ì”© ì¦ê°€ â‡’ residual block nê°œì¼ ë•Œ, connection ê²½ìš°ì˜ ìˆ˜ 2^n

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a31dc896-a9e6-4b0d-8a99-f5357bf7c82e/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T231052Z&X-Amz-Expires=86400&X-Amz-Signature=0ac73bf384eef42d7adc1ca1217a9d39badfa35fbb88945410babb976cfc75bd&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

### Overall architecture

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/bfe2df70-cc34-48cf-a3a8-7ba640c2c829/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T231108Z&X-Amz-Expires=86400&X-Amz-Signature=7f43a145db650a9018522a4472bbf49e0ca5fbf6d4ad4e4d521407ce29643b48&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

<details>
<summary>ğŸ“stride 2ë¡œ spatially down sampling í•˜ëŠ” ì´ìœ   </summary>
<div markdown="1">       

- downsampling : ì´ë¯¸ì§€ì˜ í¬ê¸°ë¥¼ ì¤„ì´ëŠ” ê³¼ì •
- ì°¸ê³  : [08. Downsampling (tistory.com)](https://preventionyun.tistory.com/32)

- Convolutional Neural Networkì—ì„œÂ **featureì˜ resolutionì„ ì¤„ì¼ ë•Œ**,Â `stride=2`Â ë˜ëŠ” Â `max/average pooling`ì„ ì´ìš©í•˜ì—¬Â **resolutionì„ 1/2ë¡œ ì¤„ì´ëŠ” ë°©ë²•**ì„ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤.
- `convolution layer`ë¥¼ ì´ìš©í•˜ì—¬Â `stride = 2`ë¡œ ì¤„ì´ë©´ í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ê°€ ì¶”ê°€ë˜ë¯€ë¡œ **í•™ìŠµ ê°€ëŠ¥í•œ ë°©ì‹ìœ¼ë¡œ resolutionì„ ì¤„ì´ê²Œ ë˜ë‚˜** ê·¸ë§Œí¼ íŒŒë¼ë¯¸í„°ì˜ ì¦ê°€ ë° ì—°ì‚°ëŸ‰ì´ ì¦ê°€í•˜ê²Œ ë©ë‹ˆë‹¤.
    - featureë¥¼ ë½‘ê¸° ìœ„í•œ Convolution Layerì™€ Downsamplingì„ ìœ„í•œ strideë¥¼ ë™ì‹œì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš° ê°™ì€ 3 x 3 í¬ê¸°ì˜ í•„í„°ë¥¼ ì‚¬ìš©í•˜ë”ë¼ë„ strideê°€ ì ìš©ë˜ê¸° ë•Œë¬¸ì—Â **ë” ë„“ì€ receptive field**ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë°˜ë©´Â `pooling`ì„ ì´ìš©í•˜ì—¬ resolutionì„ ì¤„ì´ê²Œ ë˜ë©´ **í•™ìŠµê³¼ ë¬´ê´€í•´ì§€ë©°** í•™ìŠµí•  íŒŒë¼ë¯¸í„° ì—†ì´ ì •í•´ì§„ ë°©ì‹ (max, average)ìœ¼ë¡œ resolutionì„ ì¤„ì´ê²Œ ë˜ì–´ ì—°ì‚° ë° í•™ìŠµëŸ‰ì€ ì¤„ì–´ë“¤ì§€ë§ŒÂ `convolution with stride`Â ë°©ì‹ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì§€ ëª»í•˜ë‹¤ê³  ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.
    - **layerë¥¼ ì¤„ì—¬ì„œ gradient ì „íŒŒì— ì´ˆì ì„ ë‘ë ¤ê³  í•  ë•Œ**Â poolingì„ ì‚¬ìš©í•˜ëŠ”ê²Œ ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì°¸ê³  : [Strideì™€ Poolingì˜ ë¹„êµ - gaussian37](https://gaussian37.github.io/dl-concept-stride_vs_pooling/)

</div>
</details>

<details>
<summary>ğŸ“He initializaiton  </summary>
<div markdown="1">       

- He ì´ˆê¸°í™”(He Initialization)ëŠ” `ReLU`ë¥¼ í™œì„±í™” í•¨ìˆ˜ë¡œ ì‚¬ìš©í•  ë•Œ ì¶”ì²œë˜ëŠ” ì´ˆê¸°í™” ë°©ë²•ì…ë‹ˆë‹¤.
- ì°¸ê³  : [ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” (Weight Initialization) Â· Data Science (yngie-c.github.io)](https://yngie-c.github.io/deep%20learning/2020/03/17/parameter_init/)

</div>
</details>

<details>
<summary>ğŸ“Batch normalization í•˜ëŠ” ì´ìœ   </summary>
<div markdown="1">     

- ë°°ì¹˜ ì •ê·œí™”ëŠ” ì´ˆê¸° ê°€ì¤‘ì¹˜ ì„¤ì • ë¬¸ì œì™€ ë¹„ìŠ·í•˜ê²Œ **ê°€ì¤‘ì¹˜ ì†Œë©¸ ë¬¸ì œ(Gradient Vanishing) ë˜ëŠ” ê°€ì¤‘ì¹˜ í­ë°œ ë¬¸ì œ(Gradient Exploding)ë¥¼ í•´ê²°**í•˜ê¸° ìœ„í•œ ì ‘ê·¼ ë°©ë²• ì¤‘ í•˜ë‚˜ì´ë‹¤.
- Batch normaliztion í•˜ëŠ” ì´ìœ 
    - í•™ìŠµ ì†ë„ê°€ ê°œì„ ëœë‹¤ (í•™ìŠµë¥ ì„ ë†’ê²Œ ì„¤ì •í•  ìˆ˜ ìˆê¸° ë•Œë¬¸)
    - ê°€ì¤‘ì¹˜Â ì´ˆê¹ƒê°’ ì„ íƒì˜ ì˜ì¡´ì„±ì´Â ì ì–´ì§„ë‹¤ (í•™ìŠµì„ í•  ë•Œë§ˆë‹¤ ì¶œë ¥ê°’ì„ ì •ê·œí™”í•˜ê¸° ë•Œë¬¸)
    - ê³¼ì í•©(overfitting) ìœ„í—˜ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤ (ë“œë¡­ì•„ì›ƒ ê°™ì€ ê¸°ë²• ëŒ€ì²´ ê°€ëŠ¥)
    - Gradient Vanishing ë¬¸ì œ í•´ê²°
- ì°¸ê³  : [ë¬¸ê³¼ìƒë„ ì´í•´í•˜ëŠ” ë”¥ëŸ¬ë‹ (10) - ë°°ì¹˜ ì •ê·œí™” (tistory.com)](https://sacko.tistory.com/44)

</div>
</details>

### PyTorch code for ResNet

```
return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress, **kwargs)
# BasicBlock : resnet18ì˜ ê¸°ë³¸ residual block
# [2, 2, 2, 2] : ê° layerì— ëª‡ ê°œì˜ residual blockì´ ì¡´ì¬í•˜ëŠ”ì§€ 
```

```
def _forward_impl(self, x: Tensor):
	# conv1 
	x = self.conv1(x)
	x = self.bn1(x)
	x = self.relu(x)
	x = self.maxpool(x)

	# residual block ìŒ“ê¸°
	x = self.layer1(x) # self.layer1 = self._make_layer(block=2, 64, layers[0])
	x = self.layer2(x) # self.layer2 = self._make_layer(block=2, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])
	x = self.layer3(x) # self.layer3 = self._make_layer(block=2, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])
	x = self.layer4(x) # self.layer4 = self._make_layer(block=2, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])

	# fc layer
	x = self.avgpool(x) # self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # ë²¡í„°í™”
	x = torch.flatten(x, 1) # self.fc = nn.Linear(512 * block.expansion, num_classes)
	x = self.fc(x)
	
	return x

```

```
def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int, stride: int=1, dilate: bool=False) -> nn.Sequential:
	norm_layer = self._norm_layer
	downsample = None
	previous_dilation = self.dilation
	if dilate:
		self.dilation *= stride
		stride = 1
	if stride != 1 or self.inplanes != planes * block.expansion:
		downsample = nn.Sequential(conv1x1(self.inplanes, planes * block.expansion, stride), norm_layer(planes * block.expansion),
		)

	layers = []
	layers.append(block(self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer))
	self.inplanes = planes * block.expansion
	for _ in range(1, blocks):
		layers.append(block(self.inplanes, planes, groups=self.groups, base_width=self.base_width, dilation=self.dilation, norm_layer=norm_layer))
	return nn.Sequential(*layers)
```

## Beyond ResNet

### DenseNet

- ê° layerì˜ ëª¨ë“  outputì€ channel axisë¥¼ ê¸°ì¤€ìœ¼ë¡œ `concatenate` â†’ channel ê°œìˆ˜ ëŠ˜ì–´ë‚¨ (cf. ResNetì€ `summation`)
    - alleviate **vanishing gradient problem**
    - strengthen **feature propagation**
    - encourage **the reuse of features**

### SeNet

- Attention across channels
- Recalibrates channel-wise responses by modeling interdependencies between channels
- Squeeze and excitation operations
    - `Squeeze`
        - capturing **distributions of channel-wise** responses by **global average pooling**
        <details>
        <summary>ğŸ“Squeeze  </summary>
        <div markdown="1">       
        
        - ê° ì±„ë„ë³„ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” ìš°ì„ , ê° ì±„ë„ì„ 1ì°¨ì›ìœ¼ë¡œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 3ì±„ë„ì´ ìˆìœ¼ë©´ [0.6, 0.1, 0.7]ë¡œ í‘œê¸°ë¥¼ í•´ì•¼ ê°€ì¤‘ì¹˜ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.Â **SqueezeëŠ” ê° ì±„ë„ì„ 1ì°¨ì›ìœ¼ë¡œ ë§Œë“œëŠ” ì—­í• (ì••ì¶•)ì„ í•©ë‹ˆë‹¤**.
            
        ![https://blog.kakaocdn.net/dn/Pr1cG/btq0EDXAUUE/Kn4I6j6eH4AHLFPKFF1zH1/img.png](https://blog.kakaocdn.net/dn/Pr1cG/btq0EDXAUUE/Kn4I6j6eH4AHLFPKFF1zH1/img.png)

        - SqueezeëŠ” conv ì—°ì‚°ì„ í†µí•´ ìƒì„±ëœ í”¼ì³ë§µì„ ì…ë ¥ìœ¼ë¡œ ë°›ìŠµë‹ˆë‹¤.Â **HxWxC í¬ê¸°ì˜ í”¼ì³ë§µì„** `global average pooling ì—°ì‚°`**ì„ í†µí•´ (1x1xC)ë¡œ ì••ì¶•í•©ë‹ˆë‹¤. í”¼ì²˜ë§µì˜ í•œ ì±„ë„ì— í•´ë‹¹í•˜ëŠ” í”½ì…€ ê°’ì„ ëª¨ë‘ ë‹¤ ë”í•œ ë‹¤ìŒì—, HXWë¡œ ë‚˜ëˆ„ì–´ 1x1x1ë¡œ ì••ì¶•í•©ë‹ˆë‹¤. í”¼ì³ë§µì€ Cê°œì˜ ì±„ë„ì„ ê°–ê³  ìˆìœ¼ë¯€ë¡œ ë‹¤ ì—°ê²°í•˜ë©´ (1x1xC)ê°€ ë©ë‹ˆë‹¤.**
        - ìƒì„±ëœ (1x1xC) ë²¡í„°ëŠ” Excitationìœ¼ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.
        - ì°¸ê³  : [[ë…¼ë¬¸ ì½ê¸°] SENet(2018) ë¦¬ë·°, Squeeze-and-Excitation Networks (tistory.com)](https://deep-learning-study.tistory.com/539)

        </div>
        </details>
            
    - `Excitation`
        - gating channels by **channel-wise attention weights** obtained by **a FC layer**
        <details>
        <summary>ğŸ“Excitation  </summary>
        <div markdown="1">       
        
        - **Excitationì€ Squeezeì—ì„œ ìƒì„±ëœ (1x1xC)ë²¡í„°ë¥¼ ì •ê·œí™”í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤**.
        - Excitationì€ `FC1 - ReLU - FC2 - Sigmoid`ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤. FC1ì— (1x1xC)ë°±í„°ê°€ ì…ë ¥ë˜ì–´, C ì±„ë„ì„ C/rê°œ ì±„ë„ë¡œ ì¶•ì†Œí•©ë‹ˆë‹¤. rì€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì…ë‹ˆë‹¤.
        - ì—°ì‚°ëŸ‰ ì œí•œê³¼ ì¼ë°˜í™” íš¨ê³¼ ë•Œë¬¸ì— bottleneck êµ¬ì¡°ë¥¼ ì„ íƒí–ˆë‹¤ê³  í•˜ë„¤ìš”. C/rê°œ ì±„ë„ë¡œ ì¶•ì†Œë˜ì–´ (1x1xC/r)ê°€ ëœ ë²¡í„°ëŠ” ReLUë¡œ ì „ë‹¬ë˜ê³ , FC2ë¥¼ í†µê³¼í•©ë‹ˆë‹¤. FC2ëŠ” ì±„ë„ ìˆ˜ë¥¼ ë‹¤ì‹œ Cë¡œ ë˜ëŒë¦½ë‹ˆë‹¤. ê·¸ë¦¬ê³  Sigmoidë¥¼ ê±°ì³ì„œ [0~1) ë²”ìœ„ì˜ ê°’ì„ ì§€ë‹ˆê²Œ ë©ë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, í”¼ì³ë§µê³¼ ê³±í•´ì ¸ í”¼ì³ë§µì˜ ì±„ë„ì— ê°€ì¤‘ì¹˜ë¥¼ ê°€í•©ë‹ˆë‹¤.
        - ì°¸ê³  : [[ë…¼ë¬¸ ì½ê¸°] SENet(2018) ë¦¬ë·°, Squeeze-and-Excitation Networks (tistory.com)](https://deep-learning-study.tistory.com/539)

        </div>
        </details>
            
- ~~depth â†‘ or connection ë°©ë²• ë³€í™”~~ â†’ í˜„ì¬ ì£¼ì–´ì§„ activation ê°„ì˜ ê´€ê³„ë¥¼ ëª…í™•íˆ â‡’ channel ê°„ì˜ ê´€ê³„ modeling + attention weight íŒŒì•…

    <details>
    <summary>ğŸ“ê·¸ë¦¼ ì„¤ëª…  </summary>
    <div markdown="1">       
    
    - SB Block(Squeeze(ì••ì¶•) + Excitation(ì¬ì¡°ì •))ì„ í†µí•´ **ì±„ë„ë³„ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°**í•˜ê³  **í”¼ì³ë§µì— ê³±í•´ì§€ëŠ” ëª¨ìŠµ**ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ìƒ‰ìœ¼ë¡œ í‘œí˜„ëœ ê°€ì¤‘ì¹˜ê°€ í”¼ì³ë§µê³¼ ê³±í•´ì ¸ í”¼ì³ë§µì˜ ìƒ‰ë„ ë°”ë€Œì—ˆë„¤ìš”.

    <img width="50%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/42c7e4b5-a74c-43f4-80f0-85bb0aff517e/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T231219Z&X-Amz-Expires=86400&X-Amz-Signature=3bd6c04231eda418b9c6c8f31586688a9c39c77c55b4b245ea54d6c35eee4bd2&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

    - ì°¸ê³  : [[ë…¼ë¬¸ ì½ê¸°] SENet(2018) ë¦¬ë·°, Squeeze-and-Excitation Networks (tistory.com)](https://deep-learning-study.tistory.com/539)

    </div>
    </details>

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ab4702af-77d0-4d6d-be74-6cbb5e55f57c/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T231236Z&X-Amz-Expires=86400&X-Amz-Signature=ff0237b17a5db870bc2e2ef9844c6880b03a2b16043f5b6e38cd88b89b9e046e&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

### EfficientNet

- `deep` + `wide` + `high resolution` network in an efficient way
- ì ì€ FLOPìœ¼ë¡œë„ ì„±ëŠ¥ ì¢‹ìŒ

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/75f9cb64-d4c9-46e8-918c-9b5310f8cbda/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T231252Z&X-Amz-Expires=86400&X-Amz-Signature=8cc3c7d547bfe38efe6a9ec141a8654c1ca45585381566aa08a0176249ba9833&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

<details>
<summary>ğŸ“FLOP  </summary>
<div markdown="1">       

- ë”¥ëŸ¬ë‹ì—ì„œì˜ FLOPSëŠ” ë‹¨ìœ„ ì‹œê°„ì´ ì•„ë‹Œ **ì ˆëŒ€ì ì¸ ì—°ì‚°ëŸ‰ (ê³±í•˜ê¸°, ë”í•˜ê¸° ë“±)ì˜ íšŸìˆ˜**ë¥¼ ì§€ì¹­í•©ë‹ˆë‹¤.
- ì°¸ê³  : [FLOPS (FLoating point OPerationS) - í”Œë¡­ìŠ¤ (tistory.com)](https://hongl.tistory.com/31)

</div>
</details>

<details>
<summary>ğŸ“width scaling VS. depth scaling VS. resolution scaling  </summary>
<div markdown="1">       

- ì±„ë„ì˜ ê°œìˆ˜ë¥¼ ëŠ˜ë¦¬ëŠ” `width scaling`
- ëª¨ë¸ì˜ layerë¥¼ ë°”ê¾¸ëŠ” `depth scaling`
- Input ì´ë¯¸ì§€ì˜ í•´ìƒë„(= ì´ë¯¸ì§€ í¬ê¸°)ë¥¼ ë°”ê¾¸ëŠ” `resolution scaling`
- ì°¸ê³  : [ë…¼ë¬¸ ë¦¬ë·° EfficientNet : ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ ë†’ì´ê¸° :: DOOWN (tistory.com)](https://down-develope.tistory.com/19)

</div>
</details>

<details>
<summary>ğŸ“compound scaling  </summary>
<div markdown="1">       

- ì €ìë“¤ì€ ì•„ë˜ì˜ ì¡°ê±´ì‹ìœ¼ë¡œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ìµœì ì˜ Width, Depth, Resolution scalingì´ ê°€ëŠ¥í•˜ë‹¤ê³  ì œì•ˆí•©ë‹ˆë‹¤.
    
<img width="50%" src="https://blog.kakaocdn.net/dn/YKWiA/btqSmApo2mo/pTqK0MvlwlGI4BXzDBd4W0/img.png">

- ìœ„ ì‹ì—ì„œÂ Î±,Â Î²,Â Î³ë¥¼ ì„¤ì •í•œ ë’¤Â Ï•ë¥¼ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ì— ë§ì¶”ì–´ ëŠ˜ë ¤ì£¼ë©´ ë›°ì–´ë‚œ ì„±ëŠ¥ì˜ ëª¨ë¸ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì°¸ê³  : [[ë…¼ë¬¸ ë¦¬ë·°] EfficientNet: Rethinking Model Scaling For Convolutional Neural Networks (tistory.com)](https://seing.tistory.com/138)

</div>
</details>
    

### Deformable convolution

- **2D spatial offset prediction** for irregular convolution
- **Irregular grid sampling** with 2D spatial offsets
- Implemented by `standard CNN` and grid sampling with `2D offsets`

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/48a63c46-748c-47ee-ac07-a2cb32c63d2a/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T231353Z&X-Amz-Expires=86400&X-Amz-Signature=da97ab16f33fbbc92b407ace706137f4e8343408368d634aa95501f761231e45&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">
 
<details>
<summary>ğŸ“Deformable convolution  </summary>
<div markdown="1">       

- ì—¬ëŸ¬ ì—°ì‚°(convolution, pooling, RoI pooling ë“±)ì´ **ê¸°í•˜í•™ì ìœ¼ë¡œ ì¼ì •í•œ íŒ¨í„´**ì„ ê°€ì •í•˜ê³  ìˆê¸° ë•Œë¬¸ì— **ë³µì¡í•œ transformationì— ìœ ì—°í•˜ê²Œ ëŒ€ì²˜í•˜ê¸° ì–´ë µë‹¤**ëŠ” ê²ƒì…ë‹ˆë‹¤. ì €ìë“¤ì€ ê·¸ ì˜ˆë¡œ CNN layerì—ì„œ ì‚¬ìš©í•˜ëŠ”Â [receptive field](https://www.quora.com/What-is-a-receptive-field-in-a-convolutional-neural-network)ì˜ í¬ê¸°ê°€ í•­ìƒ ê°™ê³ , object detectionì— ì‚¬ìš©í•˜ëŠ” featureë¥¼ ì–»ê¸° ìœ„í•´ ì‚¬ëŒì˜ ì‘ì—…ì´ í•„ìš”í•œ ì  ë“±ì„ ë“¤ê³  ìˆìŠµë‹ˆë‹¤.
- `Deformable Convolution`ì€ ì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ convolutionì—ì„œ ì‚¬ìš©í•˜ëŠ” **sampling gridì— 2D offsetì„ ë”í•œë‹¤**ëŠ” ì•„ì´ë””ì–´ì—ì„œ ì¶œë°œí•©ë‹ˆë‹¤.

<img width="70%" src="https://jamiekang.github.io/media/2017-04-16-deformable-convolutional-networks-fig1.png">

- ê·¸ë¦¼ (a)ì˜ ì´ˆë¡ìƒ‰ ì ì´ ì¼ë°˜ì ì¸ convolutionì˜ sampling gridì…ë‹ˆë‹¤. ì—¬ê¸°ì— offsetì„ ë”í•´(ì´ˆë¡ìƒ‰ í™”ì‚´í‘œ) (b)(c)(d)ì˜ í‘¸ë¥¸ìƒ‰ ì ë“¤ì²˜ëŸ¼ ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ë³€í˜•ì‹œì¼œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/276265a3-3efd-4729-b06e-dda92202caf1/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T231458Z&X-Amz-Expires=86400&X-Amz-Signature=71b1b8aefcf2e13c6e5390644d5711fe60de1548c6347f1908713af748988586&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

- ê·¸ë¦¼ì—ì„œ ë³´ëŠ” ê²ƒì²˜ëŸ¼ deformable convolutionì—ëŠ” ì¼ë°˜ì ì¸ convolution layer ë§ê³  í•˜ë‚˜ì˜ convolution layerê°€ ë” ìˆìŠµë‹ˆë‹¤. ê·¸ë¦¼ì—ì„œ `conv`ë¼ëŠ” ì´ë¦„ì´ ë¶™ì€ ì´ ì´ˆë¡ìƒ‰ layerê°€ **ê° ì…ë ¥ì˜ 2D offsetì„ í•™ìŠµí•˜ê¸° ìœ„í•œ ê²ƒ**ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ **offset**ì€ integer ê°’ì´ ì•„ë‹ˆë¼ fractional numberì´ê¸° ë•Œë¬¸ì— 0.5 ê°™ì€ **ì†Œìˆ˜ ê°’ì´ ê°€ëŠ¥**í•˜ë©°, **ì‹¤ì œ ê³„ì‚°ì€ linear interpolation (2Dì´ë¯€ë¡œ bilinear interpolation)ìœ¼ë¡œ ì´ë¤„ì§‘ë‹ˆë‹¤.**
- Training ê³¼ì •ì—ì„œ, output featureë¥¼ ë§Œë“œëŠ” convolution kernelê³¼ offsetì„ ì •í•˜ëŠ” convolution kernelì„ ë™ì‹œì— í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì°¸ê³  : [Deformable Convolutional Networks Â· Pull Requests to Tomorrow (jamiekang.github.io)](https://jamiekang.github.io/2017/04/16/deformable-convolutional-networks/)


</div>
</details>


# Summary of image classification

## Summary of image classification

<img width="70%" src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1461a7c7-8a94-4f02-9cab-a8c59a7851d1/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220315%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220315T231514Z&X-Amz-Expires=86400&X-Amz-Signature=5071e9cf7d688ffaa474ca2d218ae41093543588cef314f6d80b6fe3466f8b83&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject">

### AlexNet

- simple CNN architecture
- Simple computation, but heavy memory size
- Low accuracy

### VGGNet

- simple with `3x3 convolutions`
- Highest memory, the heaviest computation â†’ ì†ë„ ëŠë¦¼

### GoogLeNet

- `inception module` and `auxiliary classifier`

### ResNet

- deeper layers with `residual blocks`
- Moderate efficiency (depending on the model)
    - inception (ex. GoogleNet) ê³„ì—´ì— ë¹„í•´ ëª¨ë¸ì´ í¬ê³  ëŠë¦¼

## CNN backbones

- **AlexNet, VGG, ResNet**ì— ë¹„í•´ `GoogLeNet` is the most efficient CNN model
    - **complicated** to use
- `VGGNet` and `ResNet` are typically used as a backbone model for many tasks
    - **simple** `3x3 conv layers`

# Reference

1. CNN architectures for image classification 2
    - Szegedy et al., Going Deeper with Convolution, CVPR 2015
    - He et al., Deep Residual Learning for Image Recognition, CVPR 2015
    - Veit et al., Residual Networks Behave Like Ensembles of Relatively Shallow Networks, NIPS 2016
    - Huang et al., Densely Connected Convolutional Networks, CVPR 2017
    - Hu et al., Squeeze-and-Excitation Networks, CVPR 2018
    - Tan and Le, EfficientNet: Rethinking Model Scalinng for Convolutional Neural Networks, ICML 2019
    - Dai et al., Deformable Convolutional Networks, ICCV 2017
2. Summary of image classification
    - Canziani et al., An Analysis of Deep Neural Network Models for Practical Applications, CVPR 2016
